{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55911629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sofia\\anaconda3\\envs\\rag_droit\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "\n",
    "def parse_ceseda(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Découpe le CESEDA en articles avec contexte hiérarchique et références.\n",
    "    Hérite des infos (titre, chapitre, section, sous-section) de l’article précédent\n",
    "    si elles ne sont pas trouvées explicitement.\n",
    "    \"\"\"\n",
    "    # Regex hiérarchie\n",
    "    livre_pattern = re.compile(r\"(Livre\\s+[IVXLC]+\\s*:.*(?:\\n.*){0,2})\")\n",
    "    titre_pattern = re.compile(r\"(Titre\\s+[IVXLC]+\\s*:.*(?:\\n.*){0,2})\")\n",
    "    chapitre_pattern = re.compile(r\"(Chapitre\\s+[IVXLC]+\\s*:.*(?:\\n.*){0,2})\")\n",
    "    section_pattern = re.compile(r\"(Section\\s+\\d+\\s*:.*(?:\\n.*){0,2})\")\n",
    "    sous_section_pattern = re.compile(r\"(Sous-section\\s+\\d+\\s*:.*(?:\\n.*){0,2})\")\n",
    "    \n",
    "    # Regex article\n",
    "    article_pattern = re.compile(r\"(Article\\s+[LR]\\.?\\s*\\d+[-\\d]*\\s*:?)\")\n",
    "    \n",
    "    # Regex références internes\n",
    "    reference_pattern = re.compile(r\"article\\s+([LR]\\.?\\s*\\d+[-\\d]*)\")\n",
    "    \n",
    "    articles: Dict = {}\n",
    "    \n",
    "    # Découpage par articles\n",
    "    parts = re.split(article_pattern, text)\n",
    "    \n",
    "    for i in range(1, len(parts), 2):\n",
    "        header = parts[i].strip()\n",
    "        body = parts[i+1].strip() if i+1 < len(parts) else \"\"\n",
    "        before = parts[i-1]  # texte avant l’article\n",
    "        \n",
    "        # Récupération du contexte de l’article précédent si existant\n",
    "        prev = articles[list(articles.keys())[-1]] if articles else {}\n",
    "        current_livre = prev.get(\"livre\", \"\")\n",
    "        current_titre = prev.get(\"titre\", \"\")\n",
    "        current_chapitre = prev.get(\"chapitre\", \"\")\n",
    "        current_section = prev.get(\"section\", \"\")\n",
    "        current_sous_section = prev.get(\"sous_section\", \"\")\n",
    "        \n",
    "        # Mise à jour seulement si trouvé dans \"before\"\n",
    "        livre_match = livre_pattern.search(before)\n",
    "        if livre_match:\n",
    "            current_livre = livre_match.group(1).strip()    \n",
    "\n",
    "        titre_match = titre_pattern.search(before)\n",
    "        if titre_match:\n",
    "            current_titre = titre_match.group(1).strip()\n",
    "        \n",
    "        chapitre_match = chapitre_pattern.search(before)\n",
    "        if chapitre_match:\n",
    "            current_chapitre = chapitre_match.group(1).strip()\n",
    "        \n",
    "        section_match = section_pattern.search(before)\n",
    "        if section_match:\n",
    "            current_section = section_match.group(1).strip()\n",
    "        \n",
    "        sous_section_match = sous_section_pattern.search(before)\n",
    "        if sous_section_match:\n",
    "            current_sous_section = sous_section_match.group(1).strip()\n",
    "        \n",
    "        # Identifiant de l’article\n",
    "        article_num = re.search(r\"([LR]\\.?\\s*\\d+[-\\d]*)\", header)\n",
    "        art_code = article_num.group(1).replace(\" \", \"\") if article_num else header\n",
    "        \n",
    "        # Références citées\n",
    "        refs = [m.group(1).replace(\" \", \"\") for m in reference_pattern.finditer(body)]\n",
    "        \n",
    "        articles[art_code] = {\n",
    "            \"livre\": current_livre,\n",
    "            \"titre\": current_titre,\n",
    "            \"chapitre\": current_chapitre,\n",
    "            \"section\": current_section,\n",
    "            \"sous_section\": current_sous_section,\n",
    "            \"content\": body,\n",
    "            \"referenced\": refs\n",
    "        }\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def summerize(text: str, summarizer = summarizer, max_length: int = 500) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the given text using a pre-trained transformer model.\n",
    "    \"\"\"\n",
    "    # Summarize just the article\n",
    "    summary_article = summarizer(text, max_length=max_length, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "    return summary_article\n",
    "\n",
    "def parsed_with_summaries(articles: Dict, max_length: int = 500) -> Dict:\n",
    "    \"\"\"\n",
    "    Add summaries to each article in the parsed CESEDA\n",
    "    3 levels of summarization\n",
    "    input: article text + referenced articles + context (title, chapter, section, sub-section)\n",
    "    output: \n",
    "        - summarized text for just the article (no context, no references)\n",
    "        - summarized text for the article with context \n",
    "        - summarized text for the article with context and references\n",
    "    \n",
    "    \"\"\"\n",
    "    for art_code, art_data in articles.items():\n",
    "        art_content = art_data[\"content\"]\n",
    "        art_summary = summerize(art_content, max_length=max_length)\n",
    "        articles[art_code][\"summary_level0\"] = art_summary\n",
    "        # Add context\n",
    "        context = \" \".join(filter(None, [art_data[\"livre\"], art_data[\"titre\"], art_data[\"chapitre\"], art_data[\"section\"], art_data[\"sous_section\"]]))\n",
    "        art_with_context = context + \" \" + art_content\n",
    "        art_summary_context = summerize(art_with_context, max_length=max_length)\n",
    "        articles[art_code][\"summary_level1\"] = art_summary_context\n",
    "        # Add referenced articles\n",
    "        referenced_texts = \" \".join([articles[ref][\"content\"] for ref in art_data[\"referenced\"] if ref in articles])\n",
    "        art_with_references = art_with_context + \" \" + referenced_texts\n",
    "        art_summary_references = summerize(art_with_references, max_length=max_length)\n",
    "        articles[art_code][\"summary_level2\"] = art_summary_references\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f06a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_53456\\1797283163.py:6: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  reader = PdfReader('sources\\LEGITEXT000006070158.pdf')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L110-1: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: Le présent code régit, sous réserve du droit de l'Union européenne et des conventions internationale...\n",
      "Références: []\n",
      "-----\n",
      "L110-2: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: Le présent code est applicable sur l'ensemble du territoire de la République....\n",
      "Références: []\n",
      "-----\n",
      "L110-3: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: Sont considérées comme étrangers au sens du présent code les personnes qui n'ont pas la nationalité\n",
      "...\n",
      "Références: []\n",
      "-----\n",
      "L110-4: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: Sans préjudice du droit de l'Union européenne, le livre II du présent code régit l'entrée, le séjour...\n",
      "Références: []\n",
      "-----\n",
      "L110-5: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: A l'exception des dispositions du livre V relatives à l'asile, les dispositions du présent code ne s...\n",
      "Références: []\n",
      "-----\n",
      "L110-6: Titre I : CHAMP D'APPLICATION - \n",
      "Contenu: Tout étranger, quelle que soit la catégorie à laquelle il appartient en raison de son séjour en Fran...\n",
      "Références: []\n",
      "-----\n",
      "L121-1: Titre II : ADMINISTRATIONS EN CHARGE DE L'ENTRÉE ET\n",
      "DU SÉJOUR DES ÉTRANGERS ET DU DROIT D'ASILE\n",
      "Chapitre Ier : ÉTABLISSEMENTS PUBLICS - \n",
      "Contenu: L'Office français de l'immigration et de l'intégration est un établissement public administratif de ...\n",
      "Références: ['L.552-1', 'L.425-9']\n",
      "-----\n",
      "L121-2: Titre II : ADMINISTRATIONS EN CHARGE DE L'ENTRÉE ET\n",
      "DU SÉJOUR DES ÉTRANGERS ET DU DROIT D'ASILE\n",
      "Chapitre Ier : ÉTABLISSEMENTS PUBLICS - \n",
      "Contenu: L'Office français de l'immigration et de l'intégration est administré par un conseil d'administratio...\n",
      "Références: []\n",
      "-----\n",
      "L121-3: Titre II : ADMINISTRATIONS EN CHARGE DE L'ENTRÉE ET\n",
      "DU SÉJOUR DES ÉTRANGERS ET DU DROIT D'ASILE\n",
      "Chapitre Ier : ÉTABLISSEMENTS PUBLICS - \n",
      "Contenu: Le conseil d'administration de l'Office français de l'immigration et de l'intégration délibère sur l...\n",
      "Références: []\n",
      "-----\n",
      "L121-4: Titre II : ADMINISTRATIONS EN CHARGE DE L'ENTRÉE ET\n",
      "DU SÉJOUR DES ÉTRANGERS ET DU DROIT D'ASILE\n",
      "Chapitre Ier : ÉTABLISSEMENTS PUBLICS - \n",
      "Contenu: L'Office français de l'immigration et de l'intégration comprend un service médical.\n",
      " \n",
      "L'article L. 5...\n",
      "Références: ['L.556-11-1', 'L.121-1']\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Charger ton CESEDA brut (extrait ou texte complet)\n",
    "import pypdf\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PdfReader('sources\\LEGITEXT000006070158.pdf')\n",
    "\n",
    "# get page text without footer and header\n",
    "def get_page_text(page):\n",
    "    text = page.extract_text()\n",
    "    lines = text.split(\"\\n\")\n",
    "    content_lines = lines[:-1]\n",
    "    return \"\\n\".join(content_lines)\n",
    "\n",
    "# Parsing all the pages of pdf to extract text\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += get_page_text(page) + \"\\n\"\n",
    "articles = parse_ceseda(text)\n",
    "# Exemple d’utilisation\n",
    "for art_id, art in list(articles.items())[:10]:\n",
    "    print(f\"{art_id}: {art['titre']} - {art['chapitre']}\")\n",
    "    print(f\"Contenu: {art['content'][:100]}...\")\n",
    "    print(f\"Références: {art['referenced']}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test summarization\n",
    "articles = parsed_with_summaries(articles, max_length=50)\n",
    "print(articles['L.123-1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44321317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save articles to a json file\n",
    "import json\n",
    "\n",
    "with open('sources/parsed/ceseda_articles.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(articles, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349691fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_droit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
